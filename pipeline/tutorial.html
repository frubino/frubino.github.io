

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Tutorial &mdash; MGKit: Metagenomic framework 0.5.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Tutorial - Exploring the Data" href="Exploring-Metagenomic-Data.html" />
    <link rel="prev" title="Metagenomic Pipeline" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> MGKit: Metagenomic framework
          

          
          </a>

          
            
            
              <div class="version">
                0.5.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Metagenomic Pipeline</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">Tutorial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#initial-setup">Initial setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="#getting-sequence-data">Getting Sequence Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#taxonomy-data">Taxonomy Data</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#metagenome-assembly">Metagenome Assembly</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gene-prediction">Gene Prediction</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#using-blast">Using BLAST</a></li>
<li class="toctree-l4"><a class="reference internal" href="#using-rapsearch">Using RAPSearch</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#create-the-gff">Create the GFF</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#taxonomic-refinement">Taxonomic Refinement</a></li>
<li class="toctree-l4"><a class="reference internal" href="#complete-gff">Complete GFF</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#alignment">Alignment</a></li>
<li class="toctree-l3"><a class="reference internal" href="#coverage-and-snp-info">Coverage and SNP Info</a></li>
<li class="toctree-l3"><a class="reference internal" href="#snp-calling">SNP Calling</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#bcftools">bcftools</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#data-preparation">Data Preparation</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#diversity-analysis">Diversity Analysis</a></li>
<li class="toctree-l4"><a class="reference internal" href="#count-data">Count Data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#additional-downloads">Additional Downloads</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#full-bash-script">Full Bash Script</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="Exploring-Metagenomic-Data.html">Tutorial - Exploring the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="blast2lca.html">Profile a Community with BLAST</a></li>
<li class="toctree-l2"><a class="reference internal" href="gene_prediction.html">Gene Prediction</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../scripts/index.html">Scripts Details</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gff.html">MGKit GFF Specifications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../library.html">Library Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../changes.html">Changes</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">MGKit: Metagenomic framework</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Metagenomic Pipeline</a> &raquo;</li>
        
      <li>Tutorial</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/pipeline/tutorial.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="versionchanged" id="simple-tutorial">
<p><span class="versionmodified changed">Changed in version 0.3.4: </span>updates</p>
</div>
<div class="section" id="tutorial">
<h1>Tutorial<a class="headerlink" href="#tutorial" title="Permalink to this headline">¶</a></h1>
<p>The aim of this tutorial is to show how to build a pipeline to analyse metagenomic samples. Moreover, the SNPs calling part was made to show how diversity estimates can be calculated from metagenomic data, hence it should be changed to be more strict.</p>
<p>We’re going to use <a class="reference external" href="https://www.ebi.ac.uk/metagenomics/project/SRP000183">Peru Margin Subseafloor Biosphere</a> as an example, which can be download from the ENA website.</p>
<p>This tutorial is expected to run on a UNIX (Linux/MacOSX/Solaris), with the <cite>bash</cite> shell running, because of some of the loops (not tested with other shells).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We assume that all scripts/commands are run in the same directory.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>It is advised to run the tutorial on a cluster/server: the memory requirements for the programs used are quite high (external to the library).</p>
</div>
<div class="section" id="initial-setup">
<h2>Initial setup<a class="headerlink" href="#initial-setup" title="Permalink to this headline">¶</a></h2>
<p>We will assume that the pipeline and it’s relative packages are already installed on the system where the tutorial is run, either through a system-wide install or a virtual environment (advised). The details are in the <a class="reference internal" href="../install.html#install-ref"><span class="std std-ref">Installation</span></a> section of the documentation.</p>
<p>Also for the rest of the tutorial we assume that the following software are installed and accessible system-wide:</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://www.ebi.ac.uk/~zerbino/velvet/">Velvet</a></p></li>
<li><p><a class="reference external" href="http://bowtie-bio.sourceforge.net/bowtie2/">Bowtie 2</a></p></li>
<li><p><a class="reference external" href="http://samtools.sourceforge.net">samtools and bcftools 1.8</a></p></li>
<li><p><a class="reference external" href="http://picard.sourceforge.net">Picard Tools</a> <a class="footnote-reference brackets" href="#id3" id="id1">1</a></p></li>
<li><p><a class="reference external" href="http://www.broadinstitute.org/gatk/">GATK</a> <a class="footnote-reference brackets" href="#id4" id="id2">2</a></p></li>
<li><p><a class="reference external" href="http://www.ncbi.nlm.nih.gov/books/NBK279690/">BLAST</a> or <a class="reference external" href="http://omics.informatics.indiana.edu/mg/RAPSearch2/">RAPSearch2</a></p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="getting-sequence-data">
<h2>Getting Sequence Data<a class="headerlink" href="#getting-sequence-data" title="Permalink to this headline">¶</a></h2>
<p>The data is stored on the EBI ftp as well, and can be downloaded with the  following command (on Linux):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001326/SRR001326.fastq.gz
$ wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001325/SRR001325.fastq.gz
$ wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001323/SRR001323.fastq.gz
$ wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001322/SRR001322.fastq.gz
</pre></div>
</div>
<p>on MacOSX you can replace <cite>wget</cite> with <cite>curl -O</cite>.</p>
<p>And then uncompress with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ gunzip *.fastq.gz
</pre></div>
</div>
<div class="section" id="taxonomy-data">
<h3>Taxonomy Data<a class="headerlink" href="#taxonomy-data" title="Permalink to this headline">¶</a></h3>
<p>We only need the taxonomy for an optional part of the gene prediction for the analysis. It can be downloaded using the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ download-taxonomy.sh
</pre></div>
</div>
<p>The data will be saved in the file <cite>taxonomy.pickle</cite> to which we’ll refer from now on. More information can be found in <a class="reference internal" href="../scripts/download-taxonomy.html#download-taxonomy"><span class="std std-ref">Download Taxonomy</span></a></p>
</div>
</div>
<div class="section" id="metagenome-assembly">
<h2>Metagenome Assembly<a class="headerlink" href="#metagenome-assembly" title="Permalink to this headline">¶</a></h2>
<p>We’re going to use velvet to assemble the metagenomics sample, using the following commands in <cite>bash</cite>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ velveth velvet_work 31 -fmtAuto  *.fastq
$ velvetg velvet_work -min_contig_lgth 50
</pre></div>
</div>
<p>The contigs are in the <cite>velvet_work/contigs.fa</cite> file. We want to take out some of the information in each sequence header, to make it easier to identify them. We decided to keep only <cite>NODE_#</cite>, where # is a unique number in the file (e.g. from <cite>&gt;NODE_27_length_157_cov_703.121033</cite> we keep only <cite>&gt;NODE_27</cite>). We used this command in bash:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ cat velvet_work/contigs.fa | sed -E &#39;s/(&gt;NODE_[0-9]+)_.+/\1/g&#39; &gt; assembly.fa
</pre></div>
</div>
<p>Alternatively, <cite>fasta-utils uid</cite> can be used to avoid problems with spaces in the headers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ fasta-utils uid cat velvet_work/contigs.fa assembly.fa
</pre></div>
</div>
</div>
<div class="section" id="gene-prediction">
<h2>Gene Prediction<a class="headerlink" href="#gene-prediction" title="Permalink to this headline">¶</a></h2>
<p>Gene prediction can be done with any software that supports the tab format that BLAST outputs. Besides BLAST, RAPSearch can be used as well.</p>
<p>Before that a suitable DB must be downloaded. In this tutorial we’ll use the SwissProt portion of <cite>Uniprot &lt;http://www.uniprot.org&gt;</cite> that can be downloaded using the following commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz
$ gunzip uniprot_sprot.fasta.gz
</pre></div>
</div>
<div class="section" id="using-blast">
<h3>Using BLAST<a class="headerlink" href="#using-blast" title="Permalink to this headline">¶</a></h3>
<p>BLAST needs the DB to be indexed using the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ makeblastdb -dbtype prot -in uniprot_sprot.fasta
</pre></div>
</div>
<p>After which BLAST can be run:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ blastx -query assembly.fasta -db uniprot_sprot.fasta -out \
    assembly.uniprot.tab -outfmt 6
</pre></div>
</div>
</div>
<div class="section" id="using-rapsearch">
<h3>Using RAPSearch<a class="headerlink" href="#using-rapsearch" title="Permalink to this headline">¶</a></h3>
<p>RAPSearch is faster than BLAST, while giving similar results. As with BLAST, there is a command to be executed before it can predict genes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ prerapsearch -d uniprot_sprot.fasta -n uniprot_sprot
</pre></div>
</div>
<p>After this command is complete its execution, RAPSearch can be started:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ rapsearch -q assembly.fa -d uniprot_sprot -o assembly.uniprot.tab
</pre></div>
</div>
<p>RAPSearch will produce two files, <cite>assembly.uniprot.tab.m8</cite> and <cite>assembly.uniprot.tab.aln</cite>. <cite>assembly.uniprot.tab.m8</cite> is the file in the correct format, so we can rename it and remove the other one:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ rm assembly.uniprot.tab.aln
$ mv assembly.uniprot.tab.m8 assembly.uniprot.tab
</pre></div>
</div>
</div>
</div>
<div class="section" id="create-the-gff">
<h2>Create the GFF<a class="headerlink" href="#create-the-gff" title="Permalink to this headline">¶</a></h2>
<p>After BLAST or RAPSearch are finished, we can convert all predictions to a GFF file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ blast2gff uniprot -b 40 -db UNIPROT-SP -dbq 10 assembly.uniprot.tab \
    assembly.uniprot.gff
</pre></div>
</div>
<p>And then, because the number of annotations is high, we filter them to reduce the number of overlapping annotations:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ filter-gff overlap assembly.uniprot.gff assembly.uniprot-filt.gff
</pre></div>
</div>
<p>This will result in a smaller file. Both script supports piping, so they can be used together, for example to save a compressed file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ blast2gff uniprot -b 40 -db UNIPROT-SP -dbq 10 assembly.uniprot.tab | \
    filter-gff overlap - assembly.uniprot-filt.gff
</pre></div>
</div>
<p>Finally, rename the filtered GFF file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mv assembly.uniprot-filt.gff assembly.uniprot.gff
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>filter-gff may require a lot of memory, so it’s recommended to read its documentation for strategies on lowering the memory requirements for big datasets (a small script to sort a GFF is included <cite>sort-gff.sh</cite>)</p>
</div>
<div class="section" id="taxonomic-refinement">
<h3>Taxonomic Refinement<a class="headerlink" href="#taxonomic-refinement" title="Permalink to this headline">¶</a></h3>
<p>This section is optional, as taxonomic identifiers are assigned using Uniprot, but it can result in better identification. It requires the the <cite>nt</cite> database from NCBI to be found on the system, in the <cite>ncbi-db</cite> directory.</p>
<p>if you don’t have the <em>nt</em> database installed, it can be downloaded (&gt; 80GB uncompressed, about 30 compressed) with this command (you’ll need to install <cite>ncftpget</cite>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mkdir ncbi-db
$ cd ncbi-db
$ ncftpget ftp://ftp.ncbi.nlm.nih.gov/blast/db/nt*.gz
$ tar xfvz *.tar.gz
$ cd ..
</pre></div>
</div>
<p>To do it, first the nucleotide sequences must be extracted and then use blastn against the <cite>nt</cite> database:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ get-gff-info sequence -f assembly.fa assembly.uniprot.gff \
    assembly.uniprot.frag.fasta
$ blastn -query assembly.uniprot.frag.fasta -db ncbi-db/nt -out \
    assembly.uniprot.frag.tab -outfmt 6
</pre></div>
</div>
<p>After BLAST completes, we need to download supporting file to associate the results with the taxonomic information:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ download-ncbi-taxa.sh
$ gunzip -c ncbi-nucl-taxa.gz | taxon-utils to_hdf -n nt
</pre></div>
</div>
<p>We now need to run the <cite>taxon-utils</cite> (<a class="reference internal" href="../scripts/taxon_utils.html#taxon-utils"><span class="std std-ref">taxon-utils - Taxonomy Utilities</span></a>) script to find the LCA for each annotation. BLAST will output too many matches, so we want to also filter this file first, with <cite>filter-gff</cite>. First we convert into GFF the BLAST tab file, then use <cite>filter-gff</cite> to pick only the 95% quantile of hit length out of all hits and finally filter to get the 95% of identities. Finally run <cite>taxon-utils</cite> to get the LCA table:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ blast2gff blastdb -i 3 -r assembly.uniprot.frag.tab | \
    filter-gff sequence -t -a length -f quantile -l 0.95 -c gt | \
    filter-gff sequence -t -a identity -f quantile -l 0.95 -c gt | \
    add-gff-info addtaxa -f taxa-table.hf5:nt | \
    taxon-utils lca -b 40 -t taxonomy.pickle -s -p - lca.tab
</pre></div>
</div>
<p>What we do is convert the BLAST results into a GFF file, removing the version information from the accession. Then filter the GFF keeping only the annotation which are in the top 5% of indentity scores, but also use only annotations that have a bitscore of 40 and write the result as a 2 columns table.</p>
<p>We can now run the script to add the taxonomic information to the GFF file, with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ add-gff-info addtaxa -v -t lca.tab -a seq_id -db NCBI-NT \
    assembly.uniprot.gff assembly.uniprot-taxa.gff
</pre></div>
</div>
<p>after it completes, it is safe to rename the output GFF:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mv assembly.uniprot-taxa.gff assembly.uniprot.gff
</pre></div>
</div>
</div>
<div class="section" id="complete-gff">
<h3>Complete GFF<a class="headerlink" href="#complete-gff" title="Permalink to this headline">¶</a></h3>
<p>To add the remaining information, mapping to <a class="reference external" href="http://www.kegg.jp">KO</a> and others, including the taxonomic information, a script is provided that downloads this information into a GFF file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ add-gff-info uniprot --buffer 500 -t -e -ec -ko \
    assembly.uniprot.gff assembly.uniprot-final.gff
</pre></div>
</div>
<p>After which we can rename the GFF file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ mv assembly.uniprot-final.gff assembly.uniprot.gff
</pre></div>
</div>
</div>
</div>
<div class="section" id="alignment">
<h2>Alignment<a class="headerlink" href="#alignment" title="Permalink to this headline">¶</a></h2>
<p>The alignment of all reads to the assembly we’ll be made with <cite>bowtie2</cite>. The first step is to build the index for the reference (out assembly) with the following command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ bowtie2-build assembly.fa assembly.fa
</pre></div>
</div>
<p>and subsequently start the alignment, using bowtie2 and piping the output SAM file to <cite>samtools</cite> to convert it into BAM files with this command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> file in *.fastq<span class="p">;</span> <span class="k">do</span>
    <span class="nv">BASENAME</span><span class="o">=</span><span class="sb">`</span>basename <span class="nv">$file</span> .fastq<span class="sb">`</span>
    bowtie2 -N <span class="m">1</span> -x assembly.fa -U <span class="nv">$file</span> <span class="se">\</span>
    --very-sensitive-local <span class="se">\</span>
    --rg-id <span class="nv">$BASENAME</span> --rg PL:454 --rg PU:454 <span class="se">\</span>
    --rg SM:<span class="nv">$BASENAME</span> <span class="p">|</span> samtools view -Sb - &gt; <span class="nv">$BASENAME</span>.bam<span class="p">;</span>
<span class="k">done</span>
</pre></div>
</div>
<p>We’ll have BAM files which we need to sort and index:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> file in *.bam<span class="p">;</span> <span class="k">do</span>
    samtools sort -o <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-sort.bam <span class="nv">$file</span><span class="p">;</span>
    mv <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-sort.bam <span class="nv">$file</span>
    samtools index <span class="nv">$file</span><span class="p">;</span>
<span class="k">done</span>
</pre></div>
</div>
</div>
<div class="section" id="coverage-and-snp-info">
<h2>Coverage and SNP Info<a class="headerlink" href="#coverage-and-snp-info" title="Permalink to this headline">¶</a></h2>
<p>The coverage information is added to the GFF and needs to be added for later SNP analysis, including information about the expected number of synonymous and non-synonymous changes. The following lines can do it, using one of the scripts included with the library:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export SAMPLES=$(for file in *.bam; do echo -a `basename $file .bam`,$file ;done)
$ add-gff-info coverage $SAMPLES assembly.uniprot.gff | add-gff-info \
    exp_syn -r assembly.fa &gt; assembly.uniprot-update.gff

$ mv assembly.uniprot-update.gff assembly.uniprot.gff
$ unset SAMPLES
</pre></div>
</div>
<p>The first line prepares part of the command line for the script and stores it into an environment variable, while the last command unsets the variable, as it’s not needed anymore. The second command adds the expected number of synonymous and non-synonymous changes for each annotation.</p>
<p>A faster way to add the coverage to a GFF file is to use the <em>cov_samtools</em> command instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ for x in *.bam; do samtools depth -aa $x &gt; `basename $x .bam`.depth; done
$ add-gff-info cov_samtools $(for file in *.depth; do echo -s `basename $file .depth` -d $file ;done) assembly.uniprot.gff assembly.uniprot-update.gff
$ mv assembly.uniprot-update.gff assembly.uniprot.gff
</pre></div>
</div>
<p>This requires the creation of <em>depth</em> files from samtools, which can be fairly big. The script will accept files compressed with gzip, bzip2 (and xz if the module is available), but will be slower. For this tutorial, each uncompressed depth file is aboud 110MB.</p>
<p>The <em>coverage</em> command memory footprint is tied to the GFF file (kept in memory). The <em>cov_samtools</em> reads the depth information one line at a time and keeps a numpy array for each sequence in memory (and each sample), while the GFF is streamed.</p>
</div>
<div class="section" id="snp-calling">
<h2>SNP Calling<a class="headerlink" href="#snp-calling" title="Permalink to this headline">¶</a></h2>
<div class="section" id="bcftools">
<h3>bcftools<a class="headerlink" href="#bcftools" title="Permalink to this headline">¶</a></h3>
<p>For calling SNPs, we can use <cite>bcftools</cite> (v 1.8 was tested)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>bcftools mpileup -f assembly.fa -Ou *.bam <span class="p">|</span> bcftools call -m -v -O v --ploidy <span class="m">1</span> -A -o assembly.vcf
</pre></div>
</div>
</div>
</div>
<div class="section" id="data-preparation">
<h2>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline">¶</a></h2>
<div class="section" id="diversity-analysis">
<h3>Diversity Analysis<a class="headerlink" href="#diversity-analysis" title="Permalink to this headline">¶</a></h3>
<p>To use diversity estimates (pN/pS) for the data, we need to first first is aggregate all SNP information from the vcf file into data structures that can be read and analysed by the library. This can be done using the included script <cite>snp_parser</cite>, with this lines of bash:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ export SAMPLES=$(for file in *.bam; do echo -m `basename $file .bam`;done)
$ snp_parser -s -v -g assembly.uniprot.gff -p assembly.vcf -a assembly.fa $SAMPLES
$ unset SAMPLES
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <cite>-s</cite> options must be added if the VCF file was created with <cite>bcftools</cite></p>
</div>
</div>
<div class="section" id="count-data">
<h3>Count Data<a class="headerlink" href="#count-data" title="Permalink to this headline">¶</a></h3>
<p>To evaluate the abundance of taxa and functional categories  in the data we need to produce one file for each sample using htseq-count, from the HTSeq library.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> file in *.bam<span class="p">;</span> <span class="k">do</span>
    htseq-count -f bam -r pos -s no -t CDS -i uid -a <span class="m">8</span> <span class="se">\</span>
    -m intersection-nonempty <span class="nv">$file</span> assembly.uniprot.gff <span class="se">\</span>
    &gt; <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-counts.txt
<span class="k">done</span>
</pre></div>
</div>
<p>And to add the counts to the GFF file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ add-gff-info counts `for x in *.bam; do echo -s $(basename $x .bam); done` \
    `for x in *-counts.txt; do echo -c $x; done` assembly.uniprot.gff tmp.gff
$ mv tmp.gff assembly.uniprot.gff
</pre></div>
</div>
<p>Alternatively <cite>featureCounts</cite> from the <cite>subread</cite> package can be used:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ featureCounts -a assembly.uniprot.gff -g uid -O  -t CDS -o counts-featureCounts.txt *.bam
</pre></div>
</div>
<p>And adding it to the GFF is similar:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ add-gff-info counts `for x in *.bam; do echo -s $(basename $x .bam); done` -c counts-featureCounts.txt -e assembly.uniprot.gff tmp.gff
$ mv tmp.gff assembly.uniprot.gff
</pre></div>
</div>
<p>Note however that there will be one file only made by featureCounts and that is allowed when using <cite>add-gff-info counts</cite> when the <cite>-e</cite> option is passed.</p>
</div>
<div class="section" id="additional-downloads">
<h3>Additional Downloads<a class="headerlink" href="#additional-downloads" title="Permalink to this headline">¶</a></h3>
<p>The following files needs to be downloaded to analyse the functional categories in the following script:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget http://eggnog.embl.de/version_3.0/data/downloads/COG.members.txt.gz
$ wget http://eggnog.embl.de/version_3.0/data/downloads/NOG.members.txt.gz
$ wget http://eggnog.embl.de/version_3.0/data/downloads/COG.funccat.txt.gz
$ wget http://eggnog.embl.de/version_3.0/data/downloads/NOG.funccat.txt.gz
</pre></div>
</div>
<p>and this for Enzyme Classification:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ wget ftp://ftp.expasy.org/databases/enzyme/enzclass.txt
</pre></div>
</div>
</div>
</div>
<div class="section" id="full-bash-script">
<span id="full-script"></span><h2>Full Bash Script<a class="headerlink" href="#full-bash-script" title="Permalink to this headline">¶</a></h2>
<div class="highlight-bash notranslate"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre>  1
  2
  3
  4
  5
  6
  7
  8
  9
 10
 11
 12
 13
 14
 15
 16
 17
 18
 19
 20
 21
 22
 23
 24
 25
 26
 27
 28
 29
 30
 31
 32
 33
 34
 35
 36
 37
 38
 39
 40
 41
 42
 43
 44
 45
 46
 47
 48
 49
 50
 51
 52
 53
 54
 55
 56
 57
 58
 59
 60
 61
 62
 63
 64
 65
 66
 67
 68
 69
 70
 71
 72
 73
 74
 75
 76
 77
 78
 79
 80
 81
 82
 83
 84
 85
 86
 87
 88
 89
 90
 91
 92
 93
 94
 95
 96
 97
 98
 99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
162
163
164
165
166
167
168
169
170
171
172
173
174
175
176
177
178
179
180
181
182
183
184</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>

<span class="c1">#download data</span>
<span class="c1">#50 meters</span>
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001326/SRR001326.fastq.gz
<span class="c1">#1 meter</span>
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001325/SRR001325.fastq.gz
<span class="c1">#32 meters</span>
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001323/SRR001323.fastq.gz
<span class="c1">#16 meters</span>
wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR001/SRR001322/SRR001322.fastq.gz
<span class="c1">#uncompress data</span>
gunzip -v *.fastq.gz

<span class="c1">#assembly - preparatory phase</span>
velveth velvet_work <span class="m">31</span> -fmtAuto *.fastq
<span class="c1">#assembly</span>
velvetg velvet_work -min_contig_lgth <span class="m">50</span>
<span class="c1">#change sequence names</span>
cat velvet_work/contigs.fa <span class="p">|</span> sed -E <span class="s1">&#39;s/(&gt;NODE_[0-9]+)_.+/\1/g&#39;</span> &gt; assembly.fa
<span class="c1">#alternative</span>
<span class="c1">#fasta-utils uid cat velvet_work/contigs.fa assembly.fa</span>
<span class="c1">#remove velvet working directory</span>
rm -R velvet_work

<span class="c1">#To use the LCA option and other analysis we need a taxonomy file</span>
download-taxonomy.sh

<span class="c1">#Uniprot SwissProt DB</span>
wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz
<span class="c1">#Uncompress it</span>
gunzip uniprot_sprot.fasta.gz

<span class="c1">########</span>
<span class="c1">#Gene prediction</span>

<span class="c1">###BLAST</span>
<span class="c1">#index Uniprot</span>
makeblastdb -dbtype prot -in uniprot_sprot.fasta
<span class="c1">#Run blastx</span>
blastx -query assembly.fa -db uniprot_sprot.fasta -out <span class="se">\</span>
	assembly.uniprot.tab -outfmt <span class="m">6</span>

<span class="c1">###RAPSearch</span>
<span class="c1">#Index</span>
<span class="c1"># prerapsearch -d uniprot_sprot.fasta -n uniprot_sprot</span>
<span class="c1">#Run</span>
<span class="c1"># rapsearch -q assembly.fa -d uniprot_sprot -o assembly.uniprot.tab</span>
<span class="c1">#rename .m8 file to assembly.uniprot.tab and delete .aln</span>
<span class="c1">#rm assembly.uniprot.tab.aln</span>
<span class="c1">#mv assembly.uniprot.tab.m8 assembly.uniprot.tab</span>

<span class="c1">########</span>
<span class="c1">#Converts gene prediction into GFF annotations</span>
blast2gff uniprot -b <span class="m">40</span> -db UNIPROT-SP -dbq <span class="m">10</span> assembly.uniprot.tab <span class="se">\</span>
	assembly.uniprot.gff
filter-gff overlap assembly.uniprot.gff assembly.uniprot-filt.gff
<span class="c1">#rename the new filtered file</span>
mv assembly.uniprot-filt.gff assembly.uniprot.gff

<span class="c1">########</span>
<span class="c1">#Taxonomic refinement - requires NCBI nt DB installed and indexed</span>
<span class="nb">export</span> <span class="nv">NCBINT_DIR</span><span class="o">=</span>ncbi-db
<span class="k">if</span> <span class="o">[</span> -d <span class="s2">&quot;</span><span class="nv">$NCBINT_DIR</span><span class="s2">&quot;</span> <span class="o">]</span><span class="p">;</span> <span class="k">then</span>
	<span class="nb">echo</span> <span class="s2">&quot;Taxonomic refinement&quot;</span><span class="p">;</span>
	<span class="c1">#Extract annotations sequences</span>
	get-gff-info sequence -f assembly.fa assembly.uniprot.gff <span class="se">\</span>
        assembly.uniprot.frag.fasta
	<span class="c1">#Use blastn to match against NCBI NT</span>
	blastn -query assembly.uniprot.frag.fasta -db ncbi-db/nt -out <span class="se">\</span>
		assembly.uniprot.frag.tab -outfmt <span class="m">6</span>

	<span class="c1">#Download necessary data</span>
	download-ncbi-taxa.sh
	gunzip -c ncbi-nucl-taxa.gz <span class="p">|</span> taxon-utils to_hdf -n nt

	<span class="c1"># Get the LCA for the sequences</span>
	blast2gff blastdb -i <span class="m">3</span> -r assembly.uniprot.frag.tab <span class="p">|</span> <span class="se">\</span>
        filter-gff sequence -t -a length -f quantile -l <span class="m">0</span>.95 -c gt <span class="p">|</span> <span class="se">\</span>
        filter-gff sequence -t -a identity -f quantile -l <span class="m">0</span>.95 -c gt <span class="p">|</span> <span class="se">\</span>
        add-gff-info addtaxa -f taxa-table.hf5:nt <span class="p">|</span> <span class="se">\</span>
        taxon-utils lca -b <span class="m">40</span> -t taxonomy.pickle -s -p - lca.tab

	<span class="c1"># Add the LCA info to the GFF</span>
	add-gff-info addtaxa -v -t lca.tab -a seq_id -db NCBI-NT <span class="se">\</span>
        assembly.uniprot.gff assembly.uniprot-taxa.gff

	<span class="c1">#rename the file to continue the script</span>
	mv assembly.uniprot-taxa.gff assembly.uniprot.gff
<span class="k">fi</span>
<span class="nb">unset</span> NCBINT_DIR

<span class="c1">########</span>
<span class="c1">#Finalise information from Gene Prediction</span>
<span class="c1">#Adds remaining taxonomy, EC numbers, KO and eggNOG mappings</span>
add-gff-info uniprot --buffer <span class="m">500</span> -t -e -ec -ko <span class="se">\</span>
	assembly.uniprot.gff assembly.uniprot-final.gff
<span class="c1">#Rename the GFF</span>
mv assembly.uniprot-final.gff assembly.uniprot.gff

<span class="c1">########</span>
<span class="c1">#Alignments</span>
bowtie2-build assembly.fa assembly.fa
<span class="k">for</span> file in *.fastq<span class="p">;</span> <span class="k">do</span>
	<span class="nv">BASENAME</span><span class="o">=</span><span class="sb">`</span>basename <span class="nv">$file</span> .fastq<span class="sb">`</span><span class="p">;</span>
	bowtie2 -N <span class="m">1</span> -x assembly.fasta -U <span class="nv">$file</span> <span class="se">\</span>
	--very-sensitive-local <span class="se">\</span>
	--rg-id <span class="nv">$BASENAME</span> --rg PL:454 --rg PU:454 <span class="se">\</span>
	--rg SM:<span class="nv">$BASENAME</span> <span class="p">|</span> samtools view -Sb - &gt; <span class="nv">$BASENAME</span>.bam<span class="p">;</span>
<span class="k">done</span>
<span class="c1">#sort and index BAM files with samtools</span>
<span class="k">for</span> file in *.bam<span class="p">;</span> <span class="k">do</span>
	samtools sort <span class="nv">$file</span> <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-sort<span class="p">;</span>
	<span class="c1">#removes the unsorted file, it&#39;s not needed</span>
	mv <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-sort.bam <span class="nv">$file</span>
	samtools index <span class="nv">$file</span><span class="p">;</span>
<span class="k">done</span>

<span class="c1">########</span>
<span class="c1">#Add coverage and expected changes to GFF file</span>
<span class="c1">#export SAMPLES=$(for file in *.bam; do echo -a `basename $file .bam`,$file ;done)</span>
<span class="c1">#Coverage info</span>
<span class="c1">#add-gff-info coverage $SAMPLES assembly.uniprot.gff | add-gff-info \</span>
<span class="c1">#	exp_syn -r assembly.fa &gt; assembly.uniprot-update.gff</span>
<span class="c1">#rename to continue the script</span>
<span class="c1">#mv assembly.uniprot-update.gff assembly.uniprot.gff</span>
<span class="c1">#unset SAMPLES</span>
<span class="c1">#Faster</span>
<span class="k">for</span> x in *.bam<span class="p">;</span> <span class="k">do</span> samtools depth -aa <span class="nv">$x</span> &gt; <span class="sb">`</span>basename <span class="nv">$x</span> .bam<span class="sb">`</span>.depth<span class="p">;</span> <span class="k">done</span>
add-gff-info cov_samtools <span class="k">$(for</span> file in *.depth<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> -s <span class="sb">`</span>basename file .depth<span class="sb">`</span> -d <span class="nv">$file</span> <span class="p">;</span><span class="k">done)</span> assembly.uniprot.gff assembly.uniprot-update.gff
mv assembly.uniprot-update.gff assembly.uniprot.gff

<span class="c1">########</span>
<span class="c1">#SNP calling using samtools</span>
bcftools mpileup -f assembly.fa -Ou *.bam <span class="p">|</span> bcftools call -v -O v --ploidy <span class="m">1</span> -A -o assembly.vcf


<span class="c1">#Index fasta with Picard tools - GATK requires it</span>
<span class="c1">#java -jar picard-tools/picard.jar CreateSequenceDictionary \</span>
<span class="c1">#	R=assembly.fa O=assembly.dict</span>

<span class="c1">#merge vcf</span>
<span class="c1">#export SAMPLES=$(for file in *.bam.vcf; do echo -V:`basename $file .bam.vcf` $file ;done)</span>
<span class="c1"># java -Xmx10g -jar GATK/GenomeAnalysisTK.jar \</span>
<span class="c1"># 	  -R assembly.fa -T CombineVariants -o assembly.vcf \</span>
<span class="c1"># 	  -genotypeMergeOptions UNIQUIFY \</span>
<span class="c1"># 	  $SAMPLES</span>
<span class="c1"># unset SAMPLES</span>

<span class="c1">########</span>
<span class="c1">#snp_parser</span>
<span class="nb">export</span> <span class="nv">SAMPLES</span><span class="o">=</span><span class="k">$(for</span> file in *.bam<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> -m <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span><span class="p">;</span><span class="k">done)</span>
snp_parser -s -v -g assembly.uniprot.gff -p assembly.vcf -a assembly.fa <span class="nv">$SAMPLES</span>
<span class="nb">unset</span> SAMPLES

<span class="c1">########</span>
<span class="c1">#Count reads</span>
<span class="c1"># Using HTSeq</span>
<span class="k">for</span> file in *.bam<span class="p">;</span> <span class="k">do</span>
	htseq-count -f bam -r pos -s no -t CDS -i uid -a <span class="m">8</span> <span class="se">\</span>
	-m intersection-nonempty <span class="nv">$file</span> assembly.uniprot.gff <span class="se">\</span>
	&gt; <span class="sb">`</span>basename <span class="nv">$file</span> .bam<span class="sb">`</span>-counts.txt
<span class="k">done</span>

<span class="c1"># Adding counts to GFF</span>
add-gff-info counts <span class="sb">`</span><span class="k">for</span> x in *.bam<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> -s <span class="k">$(</span>basename <span class="nv">$x</span> .bam<span class="k">)</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span> <span class="se">\</span>
	<span class="sb">`</span><span class="k">for</span> x in *-counts.txt<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> -c <span class="nv">$x</span><span class="p">;</span> <span class="k">done</span><span class="sb">`</span> assembly.uniprot.gff tmp.gff

mv tmp.gff assembly.uniprot.gff
<span class="c1"># Using featureCounts</span>
<span class="c1">#featureCounts -a assembly.uniprot.gff -g uid -O  -t CDS -o counts-featureCounts.txt *.bam</span>
<span class="c1">#add-gff-info counts `for x in *.bam; do echo -s $(basename $x .bam); done` -c counts-featureCounts.txt -e assembly.uniprot.gff tmp.gff</span>
<span class="c1">#mv tmp.gff assembly.uniprot.gff</span>

<span class="c1">########</span>
<span class="c1">#eggNOG mappings</span>
wget http://eggnog.embl.de/version_3.0/data/downloads/COG.members.txt.gz
wget http://eggnog.embl.de/version_3.0/data/downloads/NOG.members.txt.gz
wget http://eggnog.embl.de/version_3.0/data/downloads/COG.funccat.txt.gz
wget http://eggnog.embl.de/version_3.0/data/downloads/NOG.funccat.txt.gz

<span class="c1">########</span>
<span class="c1">#EC names</span>
wget ftp://ftp.expasy.org/databases/enzyme/enzclass.txt
</pre></div>
</td></tr></table></div>
<p class="rubric">Footnotes</p>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Picard Tools needs to be found in the directory picard-tools in the same directory as this tutorial.</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>GATK directory is expected to be called <cite>GATK</cite> and inside the tutorial directory. It also needs java v1.7.x in newer versions.</p>
</dd>
</dl>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Exploring-Metagenomic-Data.html" class="btn btn-neutral float-right" title="Tutorial - Exploring the Data" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Metagenomic Pipeline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2013-2015, Francesco Rubino

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>